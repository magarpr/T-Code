import type { ModelInfo } from "../model.js"

// https://openai.com/api/pricing/
export type OpenAiNativeModelId = keyof typeof openAiNativeModels

export const openAiNativeDefaultModelId: OpenAiNativeModelId = "gpt-5"

export const openAiNativeModels = {
	"gpt-5-2025-08-07": {
		maxTokens: 128000,
		contextWindow: 400000,
		supportsImages: true,
		supportsPromptCache: true,
		supportsReasoningEffort: true,
		reasoningEffort: "medium",
		inputPrice: 1.25,
		outputPrice: 10.0,
		cacheReadsPrice: 0.13,
		description: "GPT-5: The best model for coding and agentic tasks across domains",
		// supportsVerbosity is a new capability; ensure ModelInfo includes it
		supportsVerbosity: true,
		// GPT-5 supports Responses API reasoning summaries
		supportsReasoningSummary: true,
		systemPromptRole: "developer",
		supportsTemperature: false,
	},
	"gpt-5": {
		maxTokens: 128000,
		contextWindow: 400000,
		supportsImages: true,
		supportsPromptCache: true,
		supportsReasoningEffort: true,
		reasoningEffort: "medium",
		inputPrice: 1.25,
		outputPrice: 10.0,
		cacheReadsPrice: 0.13,
		description: "GPT-5: The best model for coding and agentic tasks across domains",
		// supportsVerbosity is a new capability; ensure ModelInfo includes it
		supportsVerbosity: true,
		// GPT-5 supports Responses API reasoning summaries
		supportsReasoningSummary: true,
		systemPromptRole: "developer",
		supportsTemperature: false,
	},
	"gpt-5-mini-2025-08-07": {
		maxTokens: 128000,
		contextWindow: 400000,
		supportsImages: true,
		supportsPromptCache: true,
		supportsReasoningEffort: true,
		reasoningEffort: "medium",
		inputPrice: 0.25,
		outputPrice: 2.0,
		cacheReadsPrice: 0.03,
		description: "GPT-5 Mini: A faster, more cost-efficient version of GPT-5 for well-defined tasks",
		supportsVerbosity: true,
		// GPT-5 supports Responses API reasoning summaries
		supportsReasoningSummary: true,
		systemPromptRole: "developer",
		supportsTemperature: false,
	},
	"gpt-5-mini": {
		maxTokens: 128000,
		contextWindow: 400000,
		supportsImages: true,
		supportsPromptCache: true,
		supportsReasoningEffort: true,
		reasoningEffort: "medium",
		inputPrice: 0.25,
		outputPrice: 2.0,
		cacheReadsPrice: 0.03,
		description: "GPT-5 Mini: A faster, more cost-efficient version of GPT-5 for well-defined tasks",
		supportsVerbosity: true,
		// GPT-5 supports Responses API reasoning summaries
		supportsReasoningSummary: true,
		systemPromptRole: "developer",
		supportsTemperature: false,
	},
	"gpt-5-nano-2025-08-07": {
		maxTokens: 128000,
		contextWindow: 400000,
		supportsImages: true,
		supportsPromptCache: true,
		supportsReasoningEffort: true,
		reasoningEffort: "medium",
		inputPrice: 0.05,
		outputPrice: 0.4,
		cacheReadsPrice: 0.01,
		description: "GPT-5 Nano: Fastest, most cost-efficient version of GPT-5",
		supportsVerbosity: true,
		// GPT-5 supports Responses API reasoning summaries
		supportsReasoningSummary: true,
		systemPromptRole: "developer",
		supportsTemperature: false,
	},
	"gpt-5-nano": {
		maxTokens: 128000,
		contextWindow: 400000,
		supportsImages: true,
		supportsPromptCache: true,
		supportsReasoningEffort: true,
		reasoningEffort: "medium",
		inputPrice: 0.05,
		outputPrice: 0.4,
		cacheReadsPrice: 0.01,
		description: "GPT-5 Nano: Fastest, most cost-efficient version of GPT-5",
		supportsVerbosity: true,
		// GPT-5 supports Responses API reasoning summaries
		supportsReasoningSummary: true,
		systemPromptRole: "developer",
		supportsTemperature: false,
	},
	"gpt-4.1": {
		maxTokens: 32_768,
		contextWindow: 1_047_576,
		supportsImages: true,
		supportsPromptCache: true,
		inputPrice: 2,
		outputPrice: 8,
		cacheReadsPrice: 0.5,
		systemPromptRole: "system",
		defaultTemperature: 0,
		supportsTemperature: true,
	},
	"gpt-4.1-mini": {
		maxTokens: 32_768,
		contextWindow: 1_047_576,
		supportsImages: true,
		supportsPromptCache: true,
		inputPrice: 0.4,
		outputPrice: 1.6,
		cacheReadsPrice: 0.1,
		systemPromptRole: "system",
		defaultTemperature: 0,
		supportsTemperature: true,
	},
	"gpt-4.1-nano": {
		maxTokens: 32_768,
		contextWindow: 1_047_576,
		supportsImages: true,
		supportsPromptCache: true,
		inputPrice: 0.1,
		outputPrice: 0.4,
		cacheReadsPrice: 0.025,
		systemPromptRole: "system",
		defaultTemperature: 0,
		supportsTemperature: true,
	},
	o3: {
		maxTokens: 100_000,
		contextWindow: 200_000,
		supportsImages: true,
		supportsPromptCache: true,
		inputPrice: 2.0,
		outputPrice: 8.0,
		cacheReadsPrice: 0.5,
		supportsReasoningEffort: true,
		reasoningEffort: "medium",
		systemPromptRole: "developer",
		supportsTemperature: false,
	},
	"o4-mini": {
		maxTokens: 100_000,
		contextWindow: 200_000,
		supportsImages: true,
		supportsPromptCache: true,
		inputPrice: 1.1,
		outputPrice: 4.4,
		cacheReadsPrice: 0.275,
		supportsReasoningEffort: true,
		reasoningEffort: "medium",
		systemPromptRole: "developer",
		supportsTemperature: false,
	},
	"o3-mini": {
		maxTokens: 100_000,
		contextWindow: 200_000,
		supportsImages: false,
		supportsPromptCache: true,
		inputPrice: 1.1,
		outputPrice: 4.4,
		cacheReadsPrice: 0.55,
		supportsReasoningEffort: true,
		reasoningEffort: "medium",
		systemPromptRole: "developer",
		supportsTemperature: false,
	},
	o1: {
		maxTokens: 100_000,
		contextWindow: 200_000,
		supportsImages: true,
		supportsPromptCache: true,
		inputPrice: 15,
		outputPrice: 60,
		cacheReadsPrice: 7.5,
		systemPromptRole: "developer",
		supportsTemperature: false,
	},
	"o1-mini": {
		maxTokens: 65_536,
		contextWindow: 128_000,
		supportsImages: true,
		supportsPromptCache: true,
		inputPrice: 1.1,
		outputPrice: 4.4,
		cacheReadsPrice: 0.55,
		systemPromptRole: "developer",
		supportsTemperature: false,
	},
	"gpt-4o": {
		maxTokens: 16_384,
		contextWindow: 128_000,
		supportsImages: true,
		supportsPromptCache: true,
		inputPrice: 2.5,
		outputPrice: 10,
		cacheReadsPrice: 1.25,
		systemPromptRole: "system",
		defaultTemperature: 0,
		supportsTemperature: true,
	},
	"gpt-4o-mini": {
		maxTokens: 16_384,
		contextWindow: 128_000,
		supportsImages: true,
		supportsPromptCache: true,
		inputPrice: 0.15,
		outputPrice: 0.6,
		cacheReadsPrice: 0.075,
		systemPromptRole: "system",
		defaultTemperature: 0,
	},
	"codex-mini-latest": {
		maxTokens: 16_384,
		contextWindow: 200_000,
		supportsImages: false,
		supportsPromptCache: false,
		inputPrice: 1.5,
		outputPrice: 6,
		cacheReadsPrice: 0,
		description:
			"Codex Mini: Cloud-based software engineering agent powered by codex-1, a version of o3 optimized for coding tasks. Trained with reinforcement learning to generate human-style code, adhere to instructions, and iteratively run tests.",
	},
} as const satisfies Record<string, ModelInfo>

export const openAiModelInfoSaneDefaults: ModelInfo = {
	maxTokens: -1,
	contextWindow: 128_000,
	supportsImages: true,
	supportsPromptCache: false,
	inputPrice: 0,
	outputPrice: 0,
	defaultTemperature: 0,
}

// https://learn.microsoft.com/en-us/azure/ai-services/openai/api-version-deprecation
// https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#api-specs
export const azureOpenAiDefaultApiVersion = "2024-08-01-preview"

export const OPENAI_AZURE_AI_INFERENCE_PATH = "/models/chat/completions"
